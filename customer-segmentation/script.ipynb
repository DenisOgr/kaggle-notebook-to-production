{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03e0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import magics\n",
    "from google.oauth2 import service_account\n",
    "credentials = (service_account.Credentials.from_service_account_file(os.environ['GOOGLE_APPLICATION_CREDENTIALS']))\n",
    "magics.context.credentials = credentials\n",
    "magics.context.project = os.environ['GCP_PROJECT_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd896291",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d823e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=os.environ['GCP_PROJECT_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351f2b4",
   "metadata": {},
   "source": [
    "#### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6aa0142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(DatasetReference('kaggle-notebook-to-production', 'customer_segmentation'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_dataset(f\"{os.environ['GCP_PROJECT_ID']}.{os.environ['BQ_DATASET']}\", exists_ok=True, timeout=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3027e4",
   "metadata": {},
   "source": [
    "#### Import data to dataset table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c6433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"InvoiceNo\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"StockCode\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Description\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Quantity\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"InvoiceDate\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"UnitPrice\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"CustomerID\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"Country\", \"STRING\")\n",
    "],\n",
    "    skip_leading_rows=1,\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "source_uri=f\"gs://{os.environ['GCS_BUCKET_NAME']}/data.csv\"\n",
    "destination=f\"{os.environ['GCP_PROJECT_ID']}.{os.environ['BQ_DATASET']}._raw\"\n",
    "load_job = client.load_table_from_uri(\n",
    "    source_uri, destination, job_config=job_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a307fe",
   "metadata": {},
   "source": [
    "From origin data create table that makes PARSE_DATETIME(). Currently, in origin table, date is a string. Table name {raw}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb5b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE OR REPLACE TABLE `kaggle-notebook-to-production.customer_segmentation.raw`  AS (\n",
    "#   SELECT * EXCEPT(InvoiceDate), PARSE_DATETIME('%m/%d/%Y %H:%M', InvoiceDate) as InvoiceDate\n",
    "#   FROM `kaggle-notebook-to-production.customer_segmentation._raw` \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check\n",
    "# SELECT t1.InvoiceDate, t2.InvoiceDate \n",
    "# FROM `kaggle-notebook-to-production.customer_segmentation.raw` t1\n",
    "# INNER JOIN `kaggle-notebook-to-production.customer_segmentation._raw` t2\n",
    "# USING(InvoiceNo, StockCode, Quantity, CustomerID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bf174e",
   "metadata": {},
   "source": [
    "Check null/empty values. Run query with number of null values and relative number (%) null values for each column. Remove rows with empty value. Just query on  table {source}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT \n",
    "#   1 - COUNT(InvoiceNo)/COUNT(1) as InvoiceNo,\n",
    "#   1 - COUNT(StockCode)/COUNT(1) as StockCode,\n",
    "#   1 - COUNT(Description)/COUNT(1) as Description,\n",
    "#   1 - COUNT(Quantity)/COUNT(1) as Quantity,\n",
    "#   1 - COUNT(UnitPrice)/COUNT(1) as UnitPrice,\n",
    "#   1 - COUNT(CustomerID)/COUNT(1) as CustomerID,\n",
    "#   1 - COUNT(Country)/COUNT(1) as Country,\n",
    "#   1 - COUNT(InvoiceDate)/COUNT(1) as InvoiceDate\n",
    "# from \n",
    "# `kaggle-notebook-to-production.customer_segmentation.raw`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515617c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.source` as (\n",
    "# select * from `kaggle-notebook-to-production.customer_segmentation.raw`\n",
    "# where CustomerID is not null and Description is not null\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c826e",
   "metadata": {},
   "source": [
    "Build distribution by countries. Create table, that is ordered from most occurs country on the top. This table should include country name and relative number (%) from number of invoices (invoice and customer are a unique). Table name {by_countries}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af536ab",
   "metadata": {},
   "source": [
    "__Invoice IDs  are unique per CustomerID. It is not need to group by InvoiceId and CustomerID__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e927ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select InvoiceNo, COUNT(DISTINCT CustomerID) as cn from `kaggle-notebook-to-production.customer_segmentation.source` \n",
    "#group by InvoiceNo having cn>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT Country, count(distinct InvoiceNo) cn FROM `kaggle-notebook-to-production.customer_segmentation.source` group by Country order by cn desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd967f",
   "metadata": {},
   "source": [
    "Summary overview statistic for customers and products. Create query with number of unique customers, products and transactions. Create second table with number of product per invoice. Just query on  table {source}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af17fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT count(distinct InvoiceNo) transactions, count(distinct CustomerID) customers, count(distinct StockCode) products FROM `kaggle-notebook-to-production.customer_segmentation.source`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e57f52",
   "metadata": {},
   "source": [
    "Create and check hypothesis that for each cancelled sale exist transaction sale. That sale row should have same  CustomerID, Description and positive  Quantity. Hypothesis 1. Just query on  table {source}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select * from (\n",
    "#     SELECT \n",
    "#     *\n",
    "#     FROM `kaggle-notebook-to-production.customer_segmentation.source`\n",
    "#     WHERE Quantity < 0\n",
    "# ) t1\n",
    "# left join `kaggle-notebook-to-production.customer_segmentation.source` t2 \n",
    "# ON t1.CustomerID = t2.CustomerID and t1.Description=t2.Description and t1.Quantity = -t2.Quantity\n",
    "# WHERE t2.CustomerID is null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92752ef",
   "metadata": {},
   "source": [
    "Create and check hypothesis that each cancelled row have sale row with same StockCode and CustomerID and positive Quantity. For cancel rows Description filed should exclude word ‘Discount’. (Cancel rows should not have value ‘Discount’ in the Description column).  Just query on  table {source}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15331a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT \n",
    "# *\n",
    "# FROM `kaggle-notebook-to-production.customer_segmentation.source`\n",
    "# WHERE Quantity < 0\n",
    "# ) t2\n",
    "# WHERE t1.CustomerID = t2.CustomerID and t1.Description=t2.Description and t1.Quantity = -t2.Quantity\n",
    "# group by  t1.CustomerID, t1.Description, t2.Quantity\n",
    "# having cn > 1\n",
    "# select count(1) from (\n",
    "#     SELECT \n",
    "#     *\n",
    "#     FROM `kaggle-notebook-to-production.customer_segmentation.source`\n",
    "#     WHERE Quantity < 0 and Description != 'Discount'\n",
    "# ) t1\n",
    "# left join `kaggle-notebook-to-production.customer_segmentation.source` t2 \n",
    "# ON t1.CustomerID = t2.CustomerID and t1.Description=t2.Description and t1.Quantity = -t2.Quantity\n",
    "# WHERE t2.CustomerID is null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89fa5b",
   "metadata": {},
   "source": [
    "1. Create new field, called CancelQuantity (integer type). By default it filled by zero. Search all sale rows for each cancelled row. There are three cases:  Table name {source_v1}.\n",
    "    1. No sale rows. Just remove cancelled row.\n",
    "    2. One sale row. Set value in Quantity column from cancelled row to CancelQuantity in sale row. Remove cancelled row.\n",
    "    3. More than one sale row. Set value from Quantity column in cancelled row to most recent sale row with Quantity value that is equal or greater than Quantity in cancelled row. Remove cancelled row.\n",
    "    4. Remove all remaining rows with negative values in the Quantity column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table  `kaggle-notebook-to-production.customer_segmentation.source_v1` as (\n",
    "# with \n",
    "#     cancels as (\n",
    "#         SELECT \n",
    "#         *\n",
    "#         FROM `kaggle-notebook-to-production.customer_segmentation.source`\n",
    "#         WHERE Quantity < 0 and Description != 'Discount'\n",
    "#     ),\n",
    "\n",
    "#     sales as (\n",
    "#         SELECT \n",
    "#             *\n",
    "#             FROM `kaggle-notebook-to-production.customer_segmentation.source`\n",
    "#             WHERE Quantity >= 0\n",
    "\n",
    "#     ),\n",
    "\n",
    "#     join_cancels_sales as (\n",
    "#         select s.*, c.Quantity CancelQuantity, c.InvoiceDate  CancelDate from sales s \n",
    "#         left join cancels c \n",
    "#         on s.CustomerID = c.CustomerID and s.Description=c.Description and s.StockCode=c.StockCode\n",
    "#     ),\n",
    "#     filtered_by_date as (\n",
    "#         select * except (CancelQuantity, CancelDate), \n",
    "#         IF( CancelDate<InvoiceDate, Null, CancelQuantity) CancelQuantity,\n",
    "#         IF( CancelDate<InvoiceDate, Null, CancelDate) CancelDate   \n",
    "#         from join_cancels_sales\n",
    "#     ),\n",
    "#     filtered_by_qty as (\n",
    "#         select * except (CancelQuantity, CancelDate), \n",
    "#         IF( Quantity<-1*CancelQuantity, Null, CancelQuantity) CancelQuantity,\n",
    "#         IF( Quantity<-1*CancelQuantity, Null, CancelDate) CancelDate   \n",
    "#         from filtered_by_date\n",
    "#     ), \n",
    "#     with_number_in_multiple_sales as (\n",
    "#         select *, ROW_NUMBER() OVER (\n",
    "#             PARTITION BY StockCode, Description, CustomerID, CancelQuantity, CancelDate\n",
    "#             ORDER BY InvoiceDate DESC\n",
    "#         ) AS row_num from filtered_by_date\n",
    "#     ),\n",
    "#     filter_by_multiple_sales as (\n",
    "#         select * except (CancelQuantity, CancelDate), \n",
    "#         IF( row_num > 1, Null, CancelQuantity) CancelQuantity,\n",
    "#         IF( row_num > 1, Null, CancelDate) CancelDate   \n",
    "#         from with_number_in_multiple_sales\n",
    "#     )\n",
    "#     select * except (CancelDate, row_num, CancelQuantity), IFNULL(CancelQuantity, 0) CancelQuantity  from filter_by_multiple_sales \n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be182efd",
   "metadata": {},
   "source": [
    "#### The previous query finished with failuer. It need more time to re-produce transforming cancelled transactions into column. Currentlly, I download and use verioson from origin and load it to BQ table with name `kaggle-notebook-to-production:customer_segmentation.source_v1_from_origin`. The CSV file with data is stored here: `gs://kntp-customer-segmentation/df_cleaned.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639872d4",
   "metadata": {},
   "source": [
    "Create new column TotalPrice. This column is computed as (Quantity - CancelQuantity)  multiplied by UnitPrice. Table name {source_v2}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e05c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.source_v2` as (\n",
    "#     SELECT \n",
    "# * except (int64_field_0),((Quantity+QuantityCanceled) * UnitPrice) TotalPrice\n",
    "\n",
    "# FROM `kaggle-notebook-to-production.customer_segmentation.source_v1_from_origin`\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119669c6",
   "metadata": {},
   "source": [
    "Create new column that includes squashes (grouped) rows belonged to same InvoiceNo. The InvoiceDate should include mean values from all InvoiceDates in the one transaction. Column Basket Price equals to sum of all UnitPrice in one invoice. PS: group by Customer and Invoice. Also remove rows (that are represent invoices) with BasketPrice == 0. Table name {source_v3}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98019d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.source_v3` as (\n",
    "#     SELECT \n",
    "#     InvoiceNo, \n",
    "#     CustomerID, \n",
    "#     DATETIME(TIMESTAMP_SECONDS(cast (avg(UNIX_SECONDS(TIMESTAMP(InvoiceDate))) as INT64))) as InvoiceDate,\n",
    "#     round(sum(TotalPrice), 2) BasketPrice\n",
    "#     from `kaggle-notebook-to-production.customer_segmentation.source_v2`\n",
    "#     group by InvoiceNo, CustomerID\n",
    "#     having BasketPrice > 0\n",
    "# )\n",
    "# select DATETIME(TIMESTAMP_SECONDS(cast (avg(UNIX_SECONDS(TIMESTAMP(InvoiceDate))) as INT64))) as c from `kaggle-notebook-to-production.customer_segmentation.source_v2`\n",
    "# where InvoiceDate > '2011-01-01' and InvoiceDate <= '2011-01-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc08dd",
   "metadata": {},
   "source": [
    "Create table that  bins BasketPrice in such groups: [0, 50, 100, 200, 500, 1000, 5000, 50000] and compute the count. For example number of Invoices, placed between $0-$50 is XXX. Create table with two columns: Partition (Bin name) and count invoices. Table name {source_v4}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- [min, max)\n",
    "# DECLARE NUM_ALL_ROWS INT64;\n",
    "# SET NUM_ALL_ROWS = (SELECT count(1) from `kaggle-notebook-to-production.customer_segmentation.source_v3`);\n",
    "\n",
    "# select bin, concat(cast(round(cn/NUM_ALL_ROWS * 100, 1) as STRING), \"%\") from (\n",
    "#     SELECT \"[0, 50)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 0 and BasketPrice < 50\n",
    "#     UNION ALL \n",
    "#     SELECT \"[50, 100)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 50 and BasketPrice < 100\n",
    "#     UNION ALL \n",
    "#     SELECT \"[100, 200)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 100 and BasketPrice < 200\n",
    "#     UNION ALL \n",
    "#     SELECT \"[200, 500)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 200 and BasketPrice < 500\n",
    "#     UNION ALL \n",
    "#     SELECT \"[500, 1000)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 500 and BasketPrice < 1000\n",
    "#     UNION ALL \n",
    "#     SELECT \"[1000, 5000)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 1000 and BasketPrice < 5000\n",
    "#     UNION ALL \n",
    "#     SELECT \"[5000, 50000)\" bin,  count(1) cn FROM `kaggle-notebook-to-production.customer_segmentation.source_v3` \n",
    "#     WHERE BasketPrice >= 5000 and BasketPrice < 50000\n",
    "# ) order by cn desc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753afcce",
   "metadata": {},
   "source": [
    "1. Create categories for the product. Using descriptions of the product. This step include tree technics in  NLP: word tokenizing, steaming and pos_tagging. Steps:  \n",
    "    1. Create table with unique descriptions (maybe add Stock code for matching). Table name {descriptions}.\n",
    "    2. Iterate over each word in the description (word tokenizer), filter by noun (pos tagging) and create steam (steaming). Create two maps. Root keywords: keys is the steam of the each word and values are the actual words. Each key should include one or more values. Second map Count steams: key is the steam and values is the number of occurrences of the each keyword. \n",
    "    3. Create map (clean root keywords) with steam as key and one word as the value. In case, map root keywords include more than one words - select one with the smallest size.\n",
    "    4. Remain only steams (in clean root keywords map) that are occurred more that 13 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c6297",
   "metadata": {},
   "source": [
    "__This previous steps (NLP steps) I did not implement in BigQuery. From three technics are needed for NLP tasks: word tokenizing, steaming and pos_tagging BigQuery has only tokenizing. Thus, I import dataset from origin (pandas) approach. I imported X dataset, that includes one-hot-encoding for each description usign words. Stored in the `kaggle-notebook-to-production.customer_segmentation.description_ohe` from CSV file: `gs://kntp-customer-segmentation/ohe-descriptions_normalized.csv`__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5317ba8",
   "metadata": {},
   "source": [
    "__In the following code, I added prefix `_` to all colunm that represented the word.I do so, because there is an error, cause column has non appropriate (for BQ) name.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a746f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/ohe-descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f3aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={c:f\"_{c}\" for c in df.columns if c not in ['Description', 'Unnamed: 0']}).drop(columns=['Unnamed: 0'])\n",
    "df.to_csv('data/ohe-descriptions_normalized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa1388",
   "metadata": {},
   "source": [
    "Create table (matrix) as a feature table for build cluster K-Means model. Columns in this table are worlds (one-hot-encoding) and plus 6 addition columns. Last 6 column are representing number of bin for UnitPrice. There are following bins: [0, 1, 2, 3, 5, 10]. Table name {features_descriptions}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7eb7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.features_description` as (\n",
    "#     with \n",
    "#     mean_price_desc as (\n",
    "#         SELECT Description, round(avg(UnitPrice),2) price  FROM `kaggle-notebook-to-production.customer_segmentation.source_v2` group by Description\n",
    "#     ),\n",
    "#     ohe_mean_price_desc as (\n",
    "#         select \n",
    "#         Description,\n",
    "#         price,\n",
    "#         IF(price>=0 AND price < 1, 1, 0)  s0_f1,\n",
    "#         IF(price>=1 AND price < 2, 1, 0)  s1_f2,\n",
    "#         IF(price>=2 AND price < 3, 1, 0)  s2_f3,\n",
    "#         IF(price>=3 AND price < 5, 1, 0)  s3_f5,\n",
    "#         IF(price>=5 AND price < 10, 1, 0)  s5_f10,\n",
    "#         IF(price>=10, 1, 0)  s10_f_\n",
    "#         from mean_price_desc \n",
    "#         group by Description, price\n",
    "#     )\n",
    "#     select t1.* except (int64_field_0),\n",
    "#     t2.* except (Description) from `kaggle-notebook-to-production.customer_segmentation.description_ohe` t1\n",
    "#     inner join ohe_mean_price_desc t2 using(Description) \n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b848c8c",
   "metadata": {},
   "source": [
    "Apply k-means algorithm with 5 centroids to build the model, that can categories description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b87e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MODEL\n",
    "#   `kaggle-notebook-to-production.customer_segmentation.cat_desc_5_cent`\n",
    "# OPTIONS\n",
    "#   ( MODEL_TYPE='KMEANS',\n",
    "#     KMEANS_INIT_METHOD='KMEANS++',\n",
    "#     NUM_CLUSTERS=5 ) AS\n",
    "# SELECT\n",
    "#   * except (Description, price)\n",
    "# FROM `kaggle-notebook-to-production.customer_segmentation.features_description`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58888e38",
   "metadata": {},
   "source": [
    "__Important: BigQuery approach to create kmeans model does not create good model. That model has very imbalanced clusters. I checked the feature between pandas and BigQuery, they are same. I used the same options: init algorithm (kmeam++), number of clusters (5). But algoritm converged after 3-5 iterations. Problem: model provide cluster with 98% of all data and other 2% are spread between remaind 4 clusters. Table name: `kaggle-notebook-to-production.customer_segmentation.description_clusters`. Source file: `gs://kntp-customer-segmentation/description_clusters.csv`__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5a06f",
   "metadata": {},
   "source": [
    "Create new table from origin (before grouping by InvoiceNo) and add 6 new columns: one-hot-encode for each of 5 categories and one that represent number of the category. But instead of filling zeros and ones categorical columns, fill it with TotalPrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb363a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.source_v4` as (\n",
    "# select \n",
    "#     t1.*,\n",
    "#     IF(t2.cluster = 1, t1.TotalPrice, 0)  categ_0,\n",
    "#     IF(t2.cluster = 2, t1.TotalPrice, 0)  categ_1,\n",
    "#     IF(t2.cluster = 3, t1.TotalPrice, 0)  categ_2,\n",
    "#     IF(t2.cluster = 4, t1.TotalPrice, 0)  categ_3,\n",
    "#     IF(t2.cluster = 5, t1.TotalPrice, 0)  categ_4,\n",
    "#     t2.cluster categ_product\n",
    "# from \n",
    "#     `kaggle-notebook-to-production.customer_segmentation.source_v2` t1\n",
    "# left join  `kaggle-notebook-to-production.customer_segmentation.description_clusters` t2 using (Description)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572d89b",
   "metadata": {},
   "source": [
    "Create new table that include squashes  (grouped) rows from previous table by InvoiceNo. Each row represent each separate Invoice. Sum  categories, BasketPrice. Average the InvoiceDate. Table name {basket_price}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.basket_price` as (\n",
    "#     SELECT \n",
    "#     InvoiceNo, \n",
    "#     CustomerID, \n",
    "#     DATETIME(TIMESTAMP_SECONDS(cast (avg(UNIX_SECONDS(TIMESTAMP(InvoiceDate))) as INT64))) as InvoiceDate,\n",
    "#     round(sum(TotalPrice), 2) BasketPrice,\n",
    "#     round(sum(categ_0), 2) categ_0,\n",
    "#     round(sum(categ_1), 2) categ_1,\n",
    "#     round(sum(categ_2), 2) categ_2,\n",
    "#     round(sum(categ_3), 2) categ_3,\n",
    "#     round(sum(categ_4), 2) categ_4,\n",
    "#     from `kaggle-notebook-to-production.customer_segmentation.source_v4`\n",
    "#     group by InvoiceNo, CustomerID\n",
    "#     having BasketPrice > 0\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49501a6f",
   "metadata": {},
   "source": [
    "Split data for train and test. Use last 2 months as test dataset and remaining data for train stage. During building  customer categories and model for predicting cluster using only train dataset.  Table names {train_basket_price/test_basket_price}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6acb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.train_basket_price` as (\n",
    "#     select * from `kaggle-notebook-to-production.customer_segmentation.basket_price` where InvoiceDate <= '2011-10-01'\n",
    "# );\n",
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.test_basket_price` as (\n",
    "#     select * from `kaggle-notebook-to-production.customer_segmentation.basket_price` where InvoiceDate > '2011-10-01'\n",
    "# );\n",
    "#\n",
    "# Debug splitting.\n",
    "# SELECT 'train' as t, max(InvoiceDate), min(InvoiceDate) FROM `kaggle-notebook-to-production.customer_segmentation.train_basket_price`\n",
    "# union all \n",
    "# SELECT 'test' as t, max(InvoiceDate), min(InvoiceDate) FROM `kaggle-notebook-to-production.customer_segmentation.test_basket_price`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32ffcb",
   "metadata": {},
   "source": [
    "Create new table and squash table from 9 (squashed by Invoice) by CustomerId. Apply sum, count, min, max, mean for BasketPrice column. It spawns 5 columns. For categorical columns (5 columns) compute relative value. Sum of each category for CustomerId divided by sum of all BasketPrice multiply by 100. Add two columns that are represented number of days from first and last InvoiceDate (depend of the last day in the dataset). Table name {train_transactions_per_user}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e08c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECLARE LAST_DATE DATETIME;\n",
    "# SET LAST_DATE = (SELECT max(InvoiceDate) from `kaggle-notebook-to-production.customer_segmentation.train_basket_price`);\n",
    "\n",
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.train_transactions_per_user` as (\n",
    "#     select \n",
    "#         CustomerID,\n",
    "#         count(1) _count,\n",
    "#         min(BasketPrice) _min,\n",
    "#         max(BasketPrice) _max,\n",
    "#         round(avg(BasketPrice), 2) _avg,\n",
    "#         round(sum(BasketPrice), 2) _sum,\n",
    "#         sum(categ_0)/sum(BasketPrice)*100 categ_0,\n",
    "#         sum(categ_1)/sum(BasketPrice)*100 categ_1,\n",
    "#         sum(categ_2)/sum(BasketPrice)*100 categ_2,\n",
    "#         sum(categ_3)/sum(BasketPrice)*100 categ_3,\n",
    "#         sum(categ_4)/sum(BasketPrice)*100 categ_4,\n",
    "#         date_diff(LAST_DATE, min(InvoiceDate),DAY) as FirstPurchase,\n",
    "#         date_diff(LAST_DATE, max(InvoiceDate),DAY) as LastPurchase\n",
    "        \n",
    "#     from \n",
    "#         `kaggle-notebook-to-production.customer_segmentation.train_basket_price`\n",
    "#     group by CustomerID\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdf3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace model  `kaggle-notebook-to-production.customer_segmentation.trs_user_model_c11` \n",
    "# TRANSFORM (\n",
    "#     ML.STANDARD_SCALER(_count) OVER() _count,\n",
    "#     ML.STANDARD_SCALER(_min) OVER() _min,\n",
    "#     ML.STANDARD_SCALER(_max) OVER() _max,\n",
    "#     ML.STANDARD_SCALER(_avg) OVER() _avg,\n",
    "#     ML.STANDARD_SCALER(categ_0) OVER() categ_0,\n",
    "#     ML.STANDARD_SCALER(categ_1) OVER() categ_1,\n",
    "#     ML.STANDARD_SCALER(categ_2) OVER() categ_2,\n",
    "#     ML.STANDARD_SCALER(categ_3) OVER() categ_3,\n",
    "#     ML.STANDARD_SCALER(categ_4) OVER() categ_4\n",
    "# )\n",
    "# OPTIONS (\n",
    "#     MODEL_TYPE='KMEANS',\n",
    "#     KMEANS_INIT_METHOD='KMEANS++',\n",
    "#     NUM_CLUSTERS=11\n",
    "# )\n",
    "# as\n",
    "# SELECT * from `kaggle-notebook-to-production.customer_segmentation.train_transactions_per_user`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de6b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select CENTROID_ID, count(1) cn from \n",
    "# ML.PREDICT(MODEL `kaggle-notebook-to-production.customer_segmentation.trs_user_model_c11` ,\n",
    "#  TABLE `kaggle-notebook-to-production.customer_segmentation.train_transactions_per_user`)\n",
    "#  group by CENTROID_ID\n",
    "#  order by cn desc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ee7c2",
   "metadata": {},
   "source": [
    "Apply k-means algorithm with number of centroid equals 11. Store all fields from train_transactions_per_user and add addition one field, called, label to  Table name {labels_transactions_per_user}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd125071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create or replace table `kaggle-notebook-to-production.customer_segmentation.labels_transactions_per_user` as (\n",
    "#     select \n",
    "#         * except (NEAREST_CENTROIDS_DISTANCE, CENTROID_ID), CENTROID_ID label \n",
    "#     from \n",
    "#         ML.PREDICT(MODEL `kaggle-notebook-to-production.customer_segmentation.trs_user_model_c11` ,\n",
    "#             TABLE `kaggle-notebook-to-production.customer_segmentation.train_transactions_per_user`)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be942b",
   "metadata": {},
   "source": [
    "1. Create model for predicting cluster (category) for users with first (one) transaction (invoice):\n",
    "    1. Create feature set with ['mean', 'categ_0', 'categ_1', 'categ_2', 'categ_3', 'categ_4’ ]. Use full previous dataset (that used during building k-mean). Using Table {labels_transactions_per_user}.\n",
    "    2. Split to train and validation. Doing this in the SQL query.\n",
    "    3. Using different algorithm with grid search and cross validation number folds=5. Use: Logistic regression, XGBoost, SVM. Author applied VotingClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8c0d6",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MODEL `kaggle-notebook-to-production.customer_segmentation.cat_user_xgb`\n",
    "# OPTIONS(MODEL_TYPE='BOOSTED_TREE_CLASSIFIER',\n",
    "#         BOOSTER_TYPE = 'GBTREE',\n",
    "#         NUM_PARALLEL_TREE = 1,\n",
    "#         MAX_ITERATIONS = 40,\n",
    "#         TREE_METHOD = 'HIST',\n",
    "#         EARLY_STOP = FALSE,\n",
    "#         SUBSAMPLE = 0.8,\n",
    "#         INPUT_LABEL_COLS = ['label'])\n",
    "# AS SELECT \n",
    "#     _avg, categ_0,categ_1,categ_2,categ_3,categ_4, label\n",
    "#  FROM `kaggle-notebook-to-production.customer_segmentation.labels_transactions_per_user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9105d1",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faff397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MODEL\n",
    "#   `kaggle-notebook-to-production.customer_segmentation.cat_user_lr`\n",
    "# OPTIONS\n",
    "#   ( MODEL_TYPE='LOGISTIC_REG',\n",
    "#     AUTO_CLASS_WEIGHTS=TRUE,\n",
    "#     SUBSAMPLE = 0.8,\n",
    "#     INPUT_LABEL_COLS = ['label']\n",
    "#      ) AS\n",
    "# SELECT \n",
    "#     _avg, categ_0,categ_1,categ_2,categ_3,categ_4, label\n",
    "#  FROM `kaggle-notebook-to-production.customer_segmentation.labels_transactions_per_user`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
